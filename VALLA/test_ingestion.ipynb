{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1d1852-613f-4554-bc4b-6e4bcf519d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir\n",
    "os.path.join('../','src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a262b0-c9ea-478a-91b4-858f462a35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from av_dataset import VALLAAVTrainDataset, VALLAAVValDataset\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Add src directory to sys.path\n",
    "# Adapted from Taras Alenin's answer on StackOverflow at:\n",
    "# https://stackoverflow.com/a/55623567\n",
    "src_path = os.path.join('..', 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import custom modules\n",
    "from constants import MODEL\n",
    "from siamese_sbert import SiameseSBERT\n",
    "from modified_contrastive_loss import ModifiedContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ba0213-44d0-45f0-a24c-d1b0687e18fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 83934\n",
      "Val len: 14202\n"
     ]
    }
   ],
   "source": [
    "path_to_train_csv = '../../pan20-authorship-verification-training-small/processed/small/pan20_train.csv'\n",
    "path_to_val_csv = '../../pan20-authorship-verification-training-small/processed/small/pan20_AV_val.csv'\n",
    "train_dataset = VALLAAVTrainDataset(path_to_train_csv)\n",
    "val_dataset = VALLAAVValDataset(path_to_val_csv)\n",
    "print('Train len:', len(train_dataset))\n",
    "print('Val len:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adf0ebad-efc2-438e-a6b5-3f80ae645db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valla_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to properly batch the paired inputs.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "    labels = torch.tensor([item.label for item in batch])\n",
    "    anchor_texts = [tokenizer(item.texts[0],\n",
    "                              return_tensors=\"pt\",\n",
    "                              padding='max_length',\n",
    "                              truncation=True,\n",
    "                              max_length=512) for item in batch]\n",
    "    other_texts = [tokenizer(item.texts[1],\n",
    "                             return_tensors=\"pt\",\n",
    "                             padding='max_length',\n",
    "                             truncation=True,\n",
    "                             max_length=512) for item in batch]\n",
    "\n",
    "    # Combine input_ids and attention_masks\n",
    "    batched_a = {\n",
    "        'input_ids': torch.cat([x['input_ids'] for x in anchor_texts]),\n",
    "        'attention_mask': torch.cat([x['attention_mask']\n",
    "                                     for x in anchor_texts])\n",
    "    }\n",
    "    batched_o = {\n",
    "        'input_ids': torch.cat([x['input_ids'] for x in other_texts]),\n",
    "        'attention_mask': torch.cat([x['attention_mask']\n",
    "                                     for x in other_texts])\n",
    "    }\n",
    "\n",
    "    return batched_a, batched_o, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29021771-0ec6-4a28-aa14-1b842cc28a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseSBERT(MODEL, 'cuda').to('cuda')\n",
    "\n",
    "# Instantiate custom contrastive loss fuction\n",
    "# 'modified contrastive loss'\n",
    "loss_function = ModifiedContrastiveLoss(margin_s=0.75,\n",
    "                                        margin_d=0.25)\n",
    "\n",
    "# Instantiate Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=2e-05,\n",
    "                             eps=1e-6)\n",
    "\n",
    "\n",
    "scheduler = LinearLR(optimizer, start_factor=1.0,\n",
    "                     end_factor=0.1,\n",
    "                     total_iters=1)\n",
    "\n",
    "# Create a list to save fold losses\n",
    "fold_losses = []\n",
    "\n",
    "# Instantiate the dataloader for the train_dataset\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=valla_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe1c345-21cb-46ff-ac1e-8eccf40ac624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting batch 0\n",
      "starting batch 1\n",
      "starting batch 2\n",
      "starting batch 3\n",
      "starting batch 4\n",
      "starting batch 5\n",
      "starting batch 6\n",
      "starting batch 7\n",
      "starting batch 8\n",
      "starting batch 9\n",
      "starting batch 10\n",
      "starting batch 11\n",
      "starting batch 12\n",
      "starting batch 13\n",
      "starting batch 14\n",
      "starting batch 15\n",
      "starting batch 16\n",
      "starting batch 17\n",
      "starting batch 18\n",
      "starting batch 19\n",
      "starting batch 20\n",
      "starting batch 21\n",
      "starting batch 22\n",
      "starting batch 23\n",
      "starting batch 24\n",
      "starting batch 25\n",
      "starting batch 26\n",
      "starting batch 27\n",
      "starting batch 28\n",
      "starting batch 29\n",
      "starting batch 30\n",
      "starting batch 31\n",
      "starting batch 32\n",
      "starting batch 33\n",
      "starting batch 34\n",
      "starting batch 35\n",
      "starting batch 36\n",
      "starting batch 37\n",
      "starting batch 38\n",
      "starting batch 39\n",
      "starting batch 40\n",
      "starting batch 41\n",
      "starting batch 42\n",
      "starting batch 43\n",
      "starting batch 44\n",
      "starting batch 45\n",
      "starting batch 46\n",
      "starting batch 47\n",
      "starting batch 48\n",
      "starting batch 49\n",
      "starting batch 50\n",
      "starting batch 51\n",
      "starting batch 52\n",
      "starting batch 53\n",
      "starting batch 54\n",
      "starting batch 55\n",
      "starting batch 56\n",
      "starting batch 57\n",
      "starting batch 58\n",
      "starting batch 59\n",
      "starting batch 60\n",
      "starting batch 61\n",
      "starting batch 62\n",
      "starting batch 63\n",
      "starting batch 64\n",
      "starting batch 65\n",
      "starting batch 66\n",
      "starting batch 67\n",
      "starting batch 68\n",
      "starting batch 69\n",
      "starting batch 70\n",
      "starting batch 71\n",
      "starting batch 72\n",
      "starting batch 73\n",
      "starting batch 74\n",
      "starting batch 75\n",
      "starting batch 76\n",
      "starting batch 77\n",
      "starting batch 78\n",
      "starting batch 79\n",
      "starting batch 80\n",
      "starting batch 81\n",
      "starting batch 82\n",
      "starting batch 83\n",
      "starting batch 84\n",
      "starting batch 85\n",
      "starting batch 86\n",
      "starting batch 87\n",
      "starting batch 88\n",
      "starting batch 89\n",
      "starting batch 90\n",
      "starting batch 91\n",
      "starting batch 92\n",
      "starting batch 93\n",
      "starting batch 94\n",
      "starting batch 95\n",
      "starting batch 96\n",
      "starting batch 97\n",
      "starting batch 98\n",
      "starting batch 99\n",
      "starting batch 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m anchor_embedding, other_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_anchor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_anchor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_other\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_other\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Calculate the contrastive loss of this batch and\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# normalize by accumulation steps\u001b[39;00m\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(anchor_embedding,\n\u001b[1;32m     47\u001b[0m                      other_embedding,\n\u001b[1;32m     48\u001b[0m                      labels) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/VALLA/../src/siamese_sbert.py:108\u001b[0m, in \u001b[0;36mSiameseSBERT.forward\u001b[0;34m(self, input_ids_anchor, attention_mask_anchor, input_ids_other, attention_mask_other)\u001b[0m\n\u001b[1;32m    104\u001b[0m embeddings_anchor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_pool(\n\u001b[1;32m    105\u001b[0m     outputs_anchor\u001b[38;5;241m.\u001b[39mlast_hidden_state, attention_mask_anchor)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Encode second input\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m outputs_other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m embeddings_other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_pool(\n\u001b[1;32m    111\u001b[0m     outputs_other\u001b[38;5;241m.\u001b[39mlast_hidden_state, attention_mask_other)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings_anchor, embeddings_other\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/data/historical_av_with_SBERT/venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1108\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[1;32m   1102\u001b[0m             attention_mask,\n\u001b[1;32m   1103\u001b[0m             input_shape,\n\u001b[1;32m   1104\u001b[0m             embedding_output,\n\u001b[1;32m   1105\u001b[0m             past_key_values_length,\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1108\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "##############################################################\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Gradient Accumulation Implementation:\n",
    "# Adapted from\n",
    "# https://stackoverflow.com/a/78619879 [37]\n",
    "# Initialize running total for gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Iterate over the train_dataloader one batch at a time\n",
    "for batch_idx, (batch_anchor,\n",
    "                batch_other,\n",
    "                labels) in enumerate(train_dataloader):\n",
    "    print(f'starting batch {batch_idx}')\n",
    "    # batch_content is a tuple containing three elements\n",
    "    # coming from the PyTorch `DataLoader` object:\n",
    "    # - batch_anchor at index 0 - the batch tensor of\n",
    "    #   chunks to be fed through the 'left' side of the\n",
    "    #   Siamese network.\n",
    "    # - batch_other at index 1 - the batch tensor of\n",
    "    #   chunks to be fed through the 'right' side of the\n",
    "    #   Siamese network.\n",
    "    # - labels at index 2 - the ground truths for the\n",
    "    #   pairs:\n",
    "    #     - 1 = same-author\n",
    "    #     - 0 = different-author\n",
    "\n",
    "    # Move batches to device (MPS/CPU)\n",
    "    batch_anchor = {k: v.to('cuda')\n",
    "                    for k, v in batch_anchor.items()}\n",
    "    batch_other = {k: v.to('cuda')\n",
    "                   for k, v in batch_other.items()}\n",
    "    labels = labels.to('cuda')\n",
    "\n",
    "    # Forward pass\n",
    "    anchor_embedding, other_embedding = model(\n",
    "        batch_anchor['input_ids'],\n",
    "        batch_anchor['attention_mask'],\n",
    "        batch_other['input_ids'],\n",
    "        batch_other['attention_mask']\n",
    "    )\n",
    "    # Calculate the contrastive loss of this batch and\n",
    "    # normalize by accumulation steps\n",
    "    loss = loss_function(anchor_embedding,\n",
    "                         other_embedding,\n",
    "                         labels) / 1\n",
    "    # Save the batch loss\n",
    "    # unnormalized loss for reporting\n",
    "    fold_losses.append(loss * 1)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Adam optimizer\n",
    "    optimizer.step()\n",
    "    # Clear out any existing gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e80a97-e8bf-46e4-b3b9-f322ea011db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Historical AV with SBERT Kernel",
   "language": "python",
   "name": "historical_av_with_sbert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
